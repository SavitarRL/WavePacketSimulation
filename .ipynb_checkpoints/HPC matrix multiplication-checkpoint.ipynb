{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be4013c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import cuda, njit\n",
    "\n",
    "# CUDA kernel for matrix multiplication\n",
    "@cuda.jit\n",
    "def matrix_multi_kernel(A, B, C):\n",
    "    i, j = cuda.grid(2)\n",
    "    if i < C.shape[0] and j < C.shape[1]:\n",
    "        temp = 0.0\n",
    "        for k in range(A.shape[1]):\n",
    "            temp += A[i, k] * B[k, j]\n",
    "        C[i, j] = temp\n",
    "\n",
    "def cuda_setup(A, B):\n",
    "    # can be changed\n",
    "    num_threads_per_block = (1, 1)  # 16 each direction\n",
    "\n",
    "    # number of blocks along x to cover the rows of A\n",
    "    num_blocks_x = int(np.ceil(A.shape[0] / num_threads_per_block[0]))\n",
    "\n",
    "    # number of blocks along y to cover the columns of B\n",
    "    num_blocks_y = int(np.ceil(B.shape[1] / num_threads_per_block[1]))\n",
    "\n",
    "    # total number of blocks per grid\n",
    "    num_blocks_per_grid = (num_blocks_x, num_blocks_y)\n",
    "\n",
    "    return num_blocks_per_grid, num_threads_per_block\n",
    "\n",
    "\n",
    "def cuda_allocate(A, B):\n",
    "    # copying from CPU to GPU\n",
    "    d_A = cuda.to_device(A)\n",
    "    d_B = cuda.to_device(B)\n",
    "    # allocating device memory for result C on GPU\n",
    "    d_C = cuda.device_array((A.shape[0], B.shape[1]))\n",
    "    return d_A, d_B, d_C\n",
    "\n",
    "\n",
    "def cuda_matrix_mult(A, B):\n",
    "    # setting up dimensions of grid and block\n",
    "    num_blocks_per_grid, num_threads_per_block = cuda_setup(A, B)\n",
    "\n",
    "    # memory allocation on GPU\n",
    "    d_A, d_B, d_C = cuda_allocate(A, B)\n",
    "\n",
    "    # launching CUDA kernel\n",
    "    matrix_multi_kernel[num_blocks_per_grid, num_threads_per_block](d_A, d_B, d_C)\n",
    "\n",
    "    # Copying result back to the host\n",
    "    C = d_C.copy_to_host()\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f8d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "A = np.random.rand(32, 32)\n",
    "B = np.random.rand(32, 32)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd23904c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NvvmSupportError",
     "evalue": "No supported GPU compute capabilities found. Please check your cudatoolkit version matches your CUDA version.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNvvmSupportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29624/2446384220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# GPU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstart_time_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresult_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcuda_matrix_mult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mend_time_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgpu_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend_time_gpu\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29624/3789612358.py\u001b[0m in \u001b[0;36mcuda_matrix_mult\u001b[1;34m(A, B)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m# launching CUDA kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0mmatrix_multi_kernel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnum_blocks_per_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_threads_per_block\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_C\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;31m# Copying result back to the host\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 539\u001b[1;33m         return self.dispatcher.call(args, self.griddim, self.blockdim,\n\u001b[0m\u001b[0;32m    540\u001b[0m                                     self.stream, self.sharedmem)\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\dispatcher.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, args, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    671\u001b[0m             \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moverloads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m             \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgriddim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblockdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msharedmem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[1;34m(self, *args, **kws)\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkws\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypeof_pyval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margtypes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtypeof_pyval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\dispatcher.py\u001b[0m in \u001b[0;36mcompile\u001b[1;34m(self, sig)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Compilation disabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m             \u001b[1;31m# We call bind to force codegen, so that there is a cubin to cache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m             \u001b[0mkernel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\core\\compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\dispatcher.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, py_func, argtypes, link, debug, lineinfo, inline, fastmath, extensions, max_registers, opt, device)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# A kernel needs cooperative launch if grid_sync is being used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcooperative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'cudaCGGetIntrinsicHandle'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_asm_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m         \u001b[1;31m# We need to link against cudadevrt if grid sync is being used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcooperative\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\codegen.py\u001b[0m in \u001b[0;36mget_asm_str\u001b[1;34m(self, cc)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_asm_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_join_ptxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ptxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ptxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\codegen.py\u001b[0m in \u001b[0;36m_get_ptxes\u001b[1;34m(self, cc)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mptxes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnvvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_arch_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mcc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nvvm_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'arch'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0march\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\cudadrv\\nvvm.py\u001b[0m in \u001b[0;36mget_arch_option\u001b[1;34m(major, minor)\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFORCE_CUDA_CC\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 413\u001b[1;33m         \u001b[0march\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_closest_arch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    414\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;34m'compute_%d%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0march\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ryanl\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\numba\\cuda\\cudadrv\\nvvm.py\u001b[0m in \u001b[0;36mfind_closest_arch\u001b[1;34m(mycc)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"No supported GPU compute capabilities found. \"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m               \u001b[1;34m\"Please check your cudatoolkit version matches your CUDA version.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 386\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNvvmSupportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msupported_ccs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNvvmSupportError\u001b[0m: No supported GPU compute capabilities found. Please check your cudatoolkit version matches your CUDA version."
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# GPU \n",
    "start_time_gpu = time.time()\n",
    "result_gpu = cuda_matrix_mult(A, B)\n",
    "end_time_gpu = time.time()\n",
    "gpu_time = end_time_gpu - start_time_gpu\n",
    "print(\"GPU: {} \\n time: {}\".format(result_gpu, gpu_time))\n",
    "\n",
    "# CPU \n",
    "start_time_cpu = time.time()\n",
    "result_cpu = np.dot(A, B)\n",
    "end_time_cpu = time.time()\n",
    "cpu_time = end_time_cpu - start_time_cpu\n",
    "print(\"CPU: {} \\n time: {}\".format(result_cpu, cpu_time))\n",
    "\n",
    "\n",
    "# Check if results match\n",
    "np.testing.assert_allclose(result_gpu, result_cpu, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89bfb74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.58.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Number of Devices: ': 1,\n",
       " 'Device name: ': 'NVIDIA GeForce RTX 3060 Laptop GPU',\n",
       " 'Device properties: ': _CudaDeviceProperties(name='NVIDIA GeForce RTX 3060 Laptop GPU', major=8, minor=6, total_memory=6143MB, multi_processor_count=30)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "print(numba.__version__)\n",
    "import torch\n",
    "def gpu_info():\n",
    "    return {\"Number of Devices: \": torch.cuda.device_count(),\n",
    "            \"Device name: \": torch.cuda.get_device_name(),\n",
    "            \"Device properties: \": torch.cuda.get_device_properties(torch.cuda.device(0))}\n",
    "\n",
    "gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17743fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA device 0 'b'NVIDIA GeForce RTX 3060 Laptop GPU''>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda \n",
    "gpu = cuda.get_current_device()\n",
    "print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f7e073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Name: b'NVIDIA GeForce RTX 3060 Laptop GPU'\n",
      "Compute Capability: (8, 6)\n"
     ]
    }
   ],
   "source": [
    "import numba.cuda\n",
    "\n",
    "gpus = numba.cuda.list_devices()\n",
    "for gpu in gpus:\n",
    "    print(f\"GPU Name: {gpu.name}\")\n",
    "    print(f\"Compute Capability: {gpu.compute_capability}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386635c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
